{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "744c9d90-9733-461f-8167-c8d7bc5cf3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "#Cargamos los datos de imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "795757ce-989e-4171-b263-d697ace1a025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? true the setting in paris is great the actors are fine the story is a twisted morality play is it supposed to say that if you want someone badly enough it's ok to hurt everyone else along the way in a real romance you sort of want less cliché than the man who has become bored with his wife and is willing to dump his family and the woman who is ok with ? him to do this so what if they are decent looking and if karen allen shows off her body the characters are still self absorbed and ? maybe the moral of the story is you get what you deserve i give it a 4 only for the fast ? potential through the male interest bits\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Así se podría decodificar una reseña de imdb de vuelta a texto\n",
    "import random\n",
    "\n",
    "index = random.randint(0, len(train_data))\n",
    "\n",
    "word_index = imdb.get_word_index() #Obtiene un diccionario para mapear cada palabra a un índice numérico único\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "decoded_review = ' '.join([reverse_word_index.get(i- 3, '?') for i in train_data[index]])\n",
    "\n",
    "print(decoded_review)\n",
    "print(train_labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c09afbb-29eb-47da-8b46-286b923eefd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Codificación one-hot: vector de tamaño 10.000 donde los indices de las palabras de la reseña se establecen en 1 y el resto en 0\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    " results = np.zeros((len(sequences), dimension))\n",
    " for i, sequence in enumerate(sequences):\n",
    "     results[i, sequence] = 1.\n",
    " return results\n",
    " \n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da5ed248-14d8-44ff-b74e-e53b84e1c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f34e23ef-f57f-411b-9088-cafbdfb5dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "#Input: texto vectorizado -> Capa de 16 unidades (relu) -> Capa de 16 unidades (relu) -> Capa de 1 unidad (sigmoide) -> Output: provabilidad [0-1]\n",
    "\n",
    "model = models.Sequential()\n",
    "#model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Input(shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d8431d-e2ee-4114-95b7-1230227b922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "601b206f-5799-47fd-a130-a3c73a6152bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ffd872e-f8cd-4164-aebe-6c5d1884aab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6757 - loss: 0.6112 - val_accuracy: 0.8339 - val_loss: 0.4294\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8889 - loss: 0.3618 - val_accuracy: 0.8664 - val_loss: 0.3471\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9198 - loss: 0.2632 - val_accuracy: 0.8857 - val_loss: 0.2984\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9389 - loss: 0.2053 - val_accuracy: 0.8848 - val_loss: 0.2903\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9477 - loss: 0.1702 - val_accuracy: 0.8887 - val_loss: 0.2809\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9565 - loss: 0.1458 - val_accuracy: 0.8850 - val_loss: 0.2874\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9641 - loss: 0.1289 - val_accuracy: 0.8853 - val_loss: 0.2903\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9679 - loss: 0.1149 - val_accuracy: 0.8811 - val_loss: 0.3109\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9743 - loss: 0.0940 - val_accuracy: 0.8784 - val_loss: 0.3307\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9790 - loss: 0.0832 - val_accuracy: 0.8813 - val_loss: 0.3267\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9833 - loss: 0.0727 - val_accuracy: 0.8691 - val_loss: 0.3824\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9840 - loss: 0.0685 - val_accuracy: 0.8740 - val_loss: 0.3706\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9886 - loss: 0.0574 - val_accuracy: 0.8743 - val_loss: 0.3908\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.0565 - val_accuracy: 0.8736 - val_loss: 0.3984\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9929 - loss: 0.0425 - val_accuracy: 0.8752 - val_loss: 0.4144\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9933 - loss: 0.0380 - val_accuracy: 0.8575 - val_loss: 0.5061\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0383 - val_accuracy: 0.8715 - val_loss: 0.4521\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9961 - loss: 0.0264 - val_accuracy: 0.8702 - val_loss: 0.4710\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0238 - val_accuracy: 0.8696 - val_loss: 0.4855\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0209 - val_accuracy: 0.8687 - val_loss: 0.5082\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fd9d4d9-7340-46fd-8f61-83378b60c769",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m history_dict \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory\n\u001b[0;32m      4\u001b[0m loss_values \u001b[38;5;241m=\u001b[39m history_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c75a0fe-c7d9-4974-8bb9-44eca5a27d01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mclf()\n\u001b[0;32m      2\u001b[0m acc_values \u001b[38;5;241m=\u001b[39m history_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m val_acc_values \u001b[38;5;241m=\u001b[39m history_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    " plt.clf()\n",
    " acc_values = history_dict['acc']\n",
    " val_acc_values = history_dict['val_acc']\n",
    "\n",
    " plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    " plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    " plt.title('Training and validation accuracy')\n",
    " plt.xlabel('Epochs')\n",
    " plt.ylabel('Loss')\n",
    " plt.legend()\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "065261bc-badf-427d-b4e2-fe92b6012f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02660017],\n",
       "       [0.9999193 ],\n",
       "       [0.91328114],\n",
       "       ...,\n",
       "       [0.00318769],\n",
       "       [0.01363045],\n",
       "       [0.8855818 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e4ee723-9332-48a3-b81f-7d310aa31b14",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 16\u001b[0m\n\u001b[0;32m     11\u001b[0m             vector[index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vector\n\u001b[1;32m---> 16\u001b[0m text_review \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEscribe una reseña: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m input_vector \u001b[38;5;241m=\u001b[39m text_to_sequence(text_review)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_vector)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def text_to_sequence(text):\n",
    "    word_index = imdb.get_word_index() #Obtiene un diccionario para mapear cada palabra a un índice numérico único\n",
    "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "    words = text.lower().split()\n",
    "\n",
    "    #Creamos un vector de tamaño 10,000 y asignamos 1s en las posiciones de los índices de las palabras\n",
    "    vector = np.zeros(10000)\n",
    "    for word in words:\n",
    "        index = word_index.get(word, None)\n",
    "        if index is not None and index < 10000:  # Asegurarse de que el índice esté dentro del rango permitido\n",
    "            vector[index] = 1.0\n",
    "        \n",
    "    return vector\n",
    "\n",
    "\n",
    "text_review = input(\"Escribe una reseña: \")\n",
    "input_vector = text_to_sequence(text_review)\n",
    "\n",
    "print(input_vector)\n",
    "\n",
    "prediction = model.predict(np.array([input_vector]))\n",
    "print(f\"Reseña {\"positiva\" if prediction[0] > 0.5 else \"negativa\"}: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b1d7ce9-bb67-4e66-b0b7-9e7886b3200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creado fold: #1\n",
      "Creado fold: #2\n",
      "Creado fold: #3\n",
      "Creado fold: #4\n",
      "Analizando fold: #1\n",
      "Epoch 1/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.7069 - loss: 0.5888 - val_acc: 0.8565 - val_loss: 0.3879\n",
      "Epoch 2/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.8971 - loss: 0.3220 - val_acc: 0.8730 - val_loss: 0.3200\n",
      "Epoch 3/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9263 - loss: 0.2342 - val_acc: 0.8898 - val_loss: 0.2762\n",
      "Epoch 4/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9399 - loss: 0.1859 - val_acc: 0.8894 - val_loss: 0.2760\n",
      "Epoch 5/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9490 - loss: 0.1567 - val_acc: 0.8901 - val_loss: 0.2778\n",
      "Epoch 6/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9633 - loss: 0.1265 - val_acc: 0.8790 - val_loss: 0.3167\n",
      "Epoch 7/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9679 - loss: 0.1088 - val_acc: 0.8834 - val_loss: 0.3132\n",
      "Epoch 8/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9722 - loss: 0.0959 - val_acc: 0.8843 - val_loss: 0.3239\n",
      "Epoch 9/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9766 - loss: 0.0823 - val_acc: 0.8827 - val_loss: 0.3394\n",
      "Epoch 10/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9824 - loss: 0.0673 - val_acc: 0.8808 - val_loss: 0.3543\n",
      "Epoch 11/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9857 - loss: 0.0581 - val_acc: 0.8781 - val_loss: 0.3846\n",
      "Epoch 12/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9880 - loss: 0.0516 - val_acc: 0.8752 - val_loss: 0.3966\n",
      "Epoch 13/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9915 - loss: 0.0426 - val_acc: 0.8752 - val_loss: 0.4235\n",
      "Epoch 14/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9924 - loss: 0.0376 - val_acc: 0.8603 - val_loss: 0.5380\n",
      "Epoch 15/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9935 - loss: 0.0324 - val_acc: 0.8728 - val_loss: 0.4746\n",
      "Epoch 16/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9955 - loss: 0.0253 - val_acc: 0.8746 - val_loss: 0.4928\n",
      "Epoch 17/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9958 - loss: 0.0216 - val_acc: 0.8653 - val_loss: 0.5678\n",
      "Epoch 18/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9977 - loss: 0.0166 - val_acc: 0.8723 - val_loss: 0.5333\n",
      "Epoch 19/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9979 - loss: 0.0145 - val_acc: 0.8722 - val_loss: 0.5602\n",
      "Epoch 20/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9989 - loss: 0.0110 - val_acc: 0.8707 - val_loss: 0.5806\n",
      "Fold #1: 0.8707200288772583\n",
      "Analizando fold: #2\n",
      "Epoch 1/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.7144 - loss: 0.5619 - val_acc: 0.8656 - val_loss: 0.3594\n",
      "Epoch 2/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9003 - loss: 0.2972 - val_acc: 0.8923 - val_loss: 0.2870\n",
      "Epoch 3/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9276 - loss: 0.2197 - val_acc: 0.8936 - val_loss: 0.2726\n",
      "Epoch 4/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9424 - loss: 0.1786 - val_acc: 0.8885 - val_loss: 0.2767\n",
      "Epoch 5/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9525 - loss: 0.1516 - val_acc: 0.8896 - val_loss: 0.2802\n",
      "Epoch 6/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9598 - loss: 0.1294 - val_acc: 0.8784 - val_loss: 0.3151\n",
      "Epoch 7/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9642 - loss: 0.1152 - val_acc: 0.8824 - val_loss: 0.3242\n",
      "Epoch 8/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9711 - loss: 0.0968 - val_acc: 0.8830 - val_loss: 0.3172\n",
      "Epoch 9/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9771 - loss: 0.0864 - val_acc: 0.8818 - val_loss: 0.3338\n",
      "Epoch 10/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9799 - loss: 0.0752 - val_acc: 0.8813 - val_loss: 0.3553\n",
      "Epoch 11/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9833 - loss: 0.0643 - val_acc: 0.8790 - val_loss: 0.3889\n",
      "Epoch 12/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9871 - loss: 0.0551 - val_acc: 0.8781 - val_loss: 0.3950\n",
      "Epoch 13/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9883 - loss: 0.0496 - val_acc: 0.8797 - val_loss: 0.4298\n",
      "Epoch 14/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9904 - loss: 0.0432 - val_acc: 0.8682 - val_loss: 0.4515\n",
      "Epoch 15/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9923 - loss: 0.0381 - val_acc: 0.8728 - val_loss: 0.4660\n",
      "Epoch 16/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9936 - loss: 0.0319 - val_acc: 0.8733 - val_loss: 0.4932\n",
      "Epoch 17/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9962 - loss: 0.0254 - val_acc: 0.8682 - val_loss: 0.5112\n",
      "Epoch 18/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9967 - loss: 0.0208 - val_acc: 0.8707 - val_loss: 0.5421\n",
      "Epoch 19/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9976 - loss: 0.0180 - val_acc: 0.8683 - val_loss: 0.5594\n",
      "Epoch 20/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9981 - loss: 0.0156 - val_acc: 0.8672 - val_loss: 0.5858\n",
      "Fold #2: 0.8672000169754028\n",
      "Analizando fold: #3\n",
      "Epoch 1/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.7096 - loss: 0.5936 - val_acc: 0.8514 - val_loss: 0.3963\n",
      "Epoch 2/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.8858 - loss: 0.3475 - val_acc: 0.8819 - val_loss: 0.3093\n",
      "Epoch 3/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9191 - loss: 0.2514 - val_acc: 0.8931 - val_loss: 0.2751\n",
      "Epoch 4/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9384 - loss: 0.1958 - val_acc: 0.8915 - val_loss: 0.2827\n",
      "Epoch 5/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9441 - loss: 0.1676 - val_acc: 0.8874 - val_loss: 0.2746\n",
      "Epoch 6/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9527 - loss: 0.1458 - val_acc: 0.8867 - val_loss: 0.2838\n",
      "Epoch 7/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9623 - loss: 0.1227 - val_acc: 0.8730 - val_loss: 0.3198\n",
      "Epoch 8/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9657 - loss: 0.1153 - val_acc: 0.8747 - val_loss: 0.3323\n",
      "Epoch 9/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9737 - loss: 0.0947 - val_acc: 0.8850 - val_loss: 0.3234\n",
      "Epoch 10/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9781 - loss: 0.0804 - val_acc: 0.8747 - val_loss: 0.3672\n",
      "Epoch 11/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9834 - loss: 0.0695 - val_acc: 0.8821 - val_loss: 0.3600\n",
      "Epoch 12/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9862 - loss: 0.0575 - val_acc: 0.8675 - val_loss: 0.4268\n",
      "Epoch 13/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9865 - loss: 0.0582 - val_acc: 0.8754 - val_loss: 0.4094\n",
      "Epoch 14/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9911 - loss: 0.0435 - val_acc: 0.8773 - val_loss: 0.4266\n",
      "Epoch 15/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9934 - loss: 0.0372 - val_acc: 0.8757 - val_loss: 0.4496\n",
      "Epoch 16/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9929 - loss: 0.0337 - val_acc: 0.8722 - val_loss: 0.4716\n",
      "Epoch 17/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9954 - loss: 0.0271 - val_acc: 0.8744 - val_loss: 0.4959\n",
      "Epoch 18/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9967 - loss: 0.0233 - val_acc: 0.8704 - val_loss: 0.5191\n",
      "Epoch 19/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9978 - loss: 0.0182 - val_acc: 0.8688 - val_loss: 0.5475\n",
      "Epoch 20/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9981 - loss: 0.0158 - val_acc: 0.8686 - val_loss: 0.5736\n",
      "Fold #3: 0.8686400055885315\n",
      "Analizando fold: #4\n",
      "Epoch 1/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - acc: 0.6837 - loss: 0.6132 - val_acc: 0.8709 - val_loss: 0.4231\n",
      "Epoch 2/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.8862 - loss: 0.3696 - val_acc: 0.8816 - val_loss: 0.3254\n",
      "Epoch 3/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9149 - loss: 0.2621 - val_acc: 0.8885 - val_loss: 0.2830\n",
      "Epoch 4/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9307 - loss: 0.2100 - val_acc: 0.8938 - val_loss: 0.2684\n",
      "Epoch 5/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9442 - loss: 0.1737 - val_acc: 0.8886 - val_loss: 0.2759\n",
      "Epoch 6/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9532 - loss: 0.1476 - val_acc: 0.8915 - val_loss: 0.2774\n",
      "Epoch 7/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9595 - loss: 0.1274 - val_acc: 0.8883 - val_loss: 0.2907\n",
      "Epoch 8/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9664 - loss: 0.1109 - val_acc: 0.8834 - val_loss: 0.3051\n",
      "Epoch 9/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9714 - loss: 0.1000 - val_acc: 0.8829 - val_loss: 0.3171\n",
      "Epoch 10/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9768 - loss: 0.0844 - val_acc: 0.8792 - val_loss: 0.3400\n",
      "Epoch 11/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9787 - loss: 0.0744 - val_acc: 0.8806 - val_loss: 0.3556\n",
      "Epoch 12/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9828 - loss: 0.0664 - val_acc: 0.8784 - val_loss: 0.3809\n",
      "Epoch 13/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9880 - loss: 0.0538 - val_acc: 0.8763 - val_loss: 0.4067\n",
      "Epoch 14/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9881 - loss: 0.0506 - val_acc: 0.8742 - val_loss: 0.4611\n",
      "Epoch 15/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9925 - loss: 0.0388 - val_acc: 0.8738 - val_loss: 0.4732\n",
      "Epoch 16/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9912 - loss: 0.0386 - val_acc: 0.8640 - val_loss: 0.4937\n",
      "Epoch 17/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9937 - loss: 0.0311 - val_acc: 0.8734 - val_loss: 0.5377\n",
      "Epoch 18/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9961 - loss: 0.0247 - val_acc: 0.8718 - val_loss: 0.5156\n",
      "Epoch 19/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9968 - loss: 0.0226 - val_acc: 0.8632 - val_loss: 0.5588\n",
      "Epoch 20/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9969 - loss: 0.0199 - val_acc: 0.8722 - val_loss: 0.5628\n",
      "Fold #4: 0.872160017490387\n",
      "Media del k-fold: 0.8696800172328949\n",
      "Desviación típica del k-fold: 0.0019015816439969361\n"
     ]
    }
   ],
   "source": [
    "# Validación K-fold\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from keras import models, layers\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.0\n",
    "    return results\n",
    "\n",
    "\n",
    "# Definir el modelo\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "# Cargar y preparar los datos\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "all_data = train_data#np.concatenate((train_data, test_data))\n",
    "all_labels = train_labels#np.concatenate((train_labels, test_labels))\n",
    "\n",
    "all_data = vectorize_sequences(all_data)\n",
    "all_labels = np.array(all_labels).astype('float32')\n",
    "\n",
    "k = 4  # Número de particiones\n",
    "folds_data = []\n",
    "folds_labels = []\n",
    "\n",
    "fold_size = int(len(all_data) / k)\n",
    "for fold in range(k):\n",
    "    print(f\"Creado fold: #{fold + 1}\")\n",
    "\n",
    "    folds_data.append(all_data[fold_size * fold: fold_size * (fold + 1)])\n",
    "    folds_labels.append(all_labels[fold_size * fold: fold_size * (fold + 1)])\n",
    "num_epochs = 20\n",
    "batch_size = 512\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "# Realizar K-Fold Cross-Validation\n",
    "for fold in range(k):\n",
    "    print(f\"Analizando fold: #{fold + 1}\")\n",
    "\n",
    "    fold_training_data = np.concatenate([folds_data[i] for i in range(k) if i != fold])\n",
    "    fold_test_data = folds_data[fold]\n",
    "\n",
    "    fold_training_labels = np.concatenate([folds_labels[i] for i in range(k) if i != fold])\n",
    "    fold_test_labels = folds_labels[fold]\n",
    "\n",
    "    # Crear un nuevo modelo\n",
    "    model = build_model()\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(\n",
    "        fold_training_data, fold_training_labels,\n",
    "        epochs=num_epochs, batch_size=batch_size,\n",
    "        validation_data=(fold_test_data, fold_test_labels)\n",
    "    )\n",
    "\n",
    "    # Evaluar el modelo en los datos de validación\n",
    "    val_loss, val_acc = model.evaluate(fold_test_data, fold_test_labels, verbose=0)\n",
    "    print(f\"Fold #{fold + 1}: {val_acc}\")\n",
    "\n",
    "    all_scores.append(val_acc)  # Guardar la puntuación\n",
    "\n",
    "# Calcular el promedio de las puntuaciones\n",
    "print(f\"Media del k-fold: {np.mean(all_scores)}\")\n",
    "print(f\"Desviación típica del k-fold: {np.std(all_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1a71e-7443-4b24-b002-f9a90f8a2347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76b397-a777-423a-a676-49e47a64abd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
