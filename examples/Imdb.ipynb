{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "744c9d90-9733-461f-8167-c8d7bc5cf3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "#Cargamos los datos de imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c09afbb-29eb-47da-8b46-286b923eefd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Codificación one-hot: vector de tamaño 10.000 donde los indices de las palabras de la reseña se establecen en 1 y el resto en 0\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    " results = np.zeros((len(sequences), dimension))\n",
    " for i, sequence in enumerate(sequences):\n",
    "     results[i, sequence] = 1.\n",
    " return results\n",
    " \n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5ed248-14d8-44ff-b74e-e53b84e1c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f34e23ef-f57f-411b-9088-cafbdfb5dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "#Input: texto vectorizado -> Capa de 16 unidades (relu) -> Capa de 16 unidades (relu) -> Capa de 1 unidad (sigmoide) -> Output: provabilidad [0-1]\n",
    "\n",
    "model = models.Sequential()\n",
    "#model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Input(shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d8431d-e2ee-4114-95b7-1230227b922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "601b206f-5799-47fd-a130-a3c73a6152bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ffd872e-f8cd-4164-aebe-6c5d1884aab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.7075 - loss: 0.6043 - val_accuracy: 0.8535 - val_loss: 0.4164\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8948 - loss: 0.3569 - val_accuracy: 0.8863 - val_loss: 0.3226\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9214 - loss: 0.2557 - val_accuracy: 0.8858 - val_loss: 0.2929\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9353 - loss: 0.2079 - val_accuracy: 0.8861 - val_loss: 0.2850\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9516 - loss: 0.1655 - val_accuracy: 0.8873 - val_loss: 0.2782\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9575 - loss: 0.1433 - val_accuracy: 0.8861 - val_loss: 0.2827\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9595 - loss: 0.1286 - val_accuracy: 0.8851 - val_loss: 0.2915\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9718 - loss: 0.1072 - val_accuracy: 0.8760 - val_loss: 0.3182\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9777 - loss: 0.0895 - val_accuracy: 0.8826 - val_loss: 0.3187\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9820 - loss: 0.0741 - val_accuracy: 0.8724 - val_loss: 0.3523\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.0654 - val_accuracy: 0.8519 - val_loss: 0.4414\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9837 - loss: 0.0614 - val_accuracy: 0.8713 - val_loss: 0.3788\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9901 - loss: 0.0483 - val_accuracy: 0.8708 - val_loss: 0.3973\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9924 - loss: 0.0408 - val_accuracy: 0.8714 - val_loss: 0.4586\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0354 - val_accuracy: 0.8684 - val_loss: 0.4433\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0327 - val_accuracy: 0.8746 - val_loss: 0.4665\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0227 - val_accuracy: 0.8545 - val_loss: 0.5395\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0246 - val_accuracy: 0.8708 - val_loss: 0.5038\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0159 - val_accuracy: 0.8693 - val_loss: 0.5259\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9994 - loss: 0.0130 - val_accuracy: 0.8668 - val_loss: 0.6012\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9d4d9-7340-46fd-8f61-83378b60c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75a0fe-c7d9-4974-8bb9-44eca5a27d01",
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.clf()\n",
    " acc_values = history_dict['acc']\n",
    " val_acc_values = history_dict['val_acc']\n",
    "\n",
    " plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    " plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    " plt.title('Training and validation accuracy')\n",
    " plt.xlabel('Epochs')\n",
    " plt.ylabel('Loss')\n",
    " plt.legend()\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "795757ce-989e-4171-b263-d697ace1a025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 0. 0. 0.]\n",
      " i just finished watching this film and wow was that bad actually the only thing that kept me watching was that it was so  bad it was kind of entertaining the action of the characters is hilarious from the hyper dramatic way they fall to  to their incredibly bad acting were the bad guys all just pulled off the street or were they actually actors to incredibly bad delivery of lines to their inexplicable actions if you are going to try and shoot someone through a  as they enter obviously the thing to do is shoot directly at the  this film must break some record for worst written and delivered lines br br the camera work was also really bad you can hardly see what's going on in the fight scenes due to switching camera angles and  br br i would have voted 1 except that i do like chiba and sidekick sue  and i was entertained by a couple of scenes 1 breaking of a  arm so the bone pops out of the skin that's gotta hurt 2 a drug  eating a brown  animal a monkey by  away at the  with a meat  3 sonny  performing some  eye surgery on a guy with his fingers br br i am actually a big fan of sonny chiba but this one is really not worth anyone's time i've seen about 7 or 8 of his films and have come to the conclusion that the only ones worth watching and they are great are the street fighter series and the killing machine i've also heard the  and  13 are good i recommend sticking to those ones\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Así se podría decodificar una reseña de imdb de vuelta a texto\n",
    "import random\n",
    "\n",
    "index = random.randint(0, len(train_data))\n",
    "\n",
    "word_index = imdb.get_word_index() #Obtiene un diccionario para mapear cada palabra a un índice numérico único\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "decoded_review = ' '.join([reverse_word_index.get(i- 3, '') for i in train_data[index]]) #IMBD reserva los 3 primeros indices para caracteres y palabras desconocidos.\n",
    "\n",
    "print(x_train[index])\n",
    "print(decoded_review)\n",
    "print(train_labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18ee127b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Escribe una reseña:  es una puta mierda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Reseña positiva: [0.5229162]\n"
     ]
    }
   ],
   "source": [
    "def text_to_sequence(text):\n",
    "    word_index = imdb.get_word_index() #Obtiene un diccionario para mapear cada palabra a un índice numérico único\n",
    "    words = text.lower().split()\n",
    "\n",
    "    #Creamos un vector de tamaño 10,000 y asignamos 1s en las posiciones de los índices de las palabras\n",
    "    vector = np.zeros(10000)\n",
    "    for word in words:\n",
    "        index = word_index.get(word, None)\n",
    "        if index is not None and index < 10000:  # Asegurarse de que el índice esté dentro del rango permitido\n",
    "            vector[index +3] = 1.0\n",
    "        \n",
    "    return vector\n",
    "\n",
    "\n",
    "text_review = input(\"Escribe una reseña: \")\n",
    "input_vector = text_to_sequence(text_review)\n",
    "\n",
    "print(input_vector)\n",
    "\n",
    "prediction = model.predict(np.array([input_vector]))\n",
    "print(f\"Reseña {\"positiva\" if prediction[0] > 0.5 else \"negativa\"}: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b1d7ce9-bb67-4e66-b0b7-9e7886b3200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creado fold: #1\n",
      "Creado fold: #2\n",
      "Creado fold: #3\n",
      "Creado fold: #4\n",
      "Analizando fold: #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\izan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.6967 - loss: 0.5888 - val_acc: 0.8715 - val_loss: 0.3582\n",
      "Epoch 2/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9020 - loss: 0.3023 - val_acc: 0.8845 - val_loss: 0.2932\n",
      "Epoch 3/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9258 - loss: 0.2235 - val_acc: 0.8765 - val_loss: 0.2992\n",
      "Epoch 4/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9356 - loss: 0.1846 - val_acc: 0.8915 - val_loss: 0.2730\n",
      "Epoch 5/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9495 - loss: 0.1530 - val_acc: 0.8904 - val_loss: 0.2796\n",
      "Epoch 6/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9593 - loss: 0.1276 - val_acc: 0.8667 - val_loss: 0.3399\n",
      "Epoch 7/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9625 - loss: 0.1175 - val_acc: 0.8886 - val_loss: 0.3044\n",
      "Epoch 8/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9719 - loss: 0.0960 - val_acc: 0.8811 - val_loss: 0.3326\n",
      "Epoch 9/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9772 - loss: 0.0820 - val_acc: 0.8832 - val_loss: 0.3459\n",
      "Epoch 10/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9819 - loss: 0.0689 - val_acc: 0.8821 - val_loss: 0.3689\n",
      "Epoch 11/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9857 - loss: 0.0602 - val_acc: 0.8744 - val_loss: 0.4168\n",
      "Epoch 12/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9862 - loss: 0.0563 - val_acc: 0.8610 - val_loss: 0.5163\n",
      "Epoch 13/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9880 - loss: 0.0491 - val_acc: 0.8770 - val_loss: 0.4339\n",
      "Epoch 14/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9908 - loss: 0.0388 - val_acc: 0.8754 - val_loss: 0.4604\n",
      "Epoch 15/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9924 - loss: 0.0342 - val_acc: 0.8610 - val_loss: 0.5319\n",
      "Epoch 16/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9945 - loss: 0.0288 - val_acc: 0.8746 - val_loss: 0.5078\n",
      "Epoch 17/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9964 - loss: 0.0224 - val_acc: 0.8742 - val_loss: 0.5370\n",
      "Epoch 18/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9966 - loss: 0.0201 - val_acc: 0.8720 - val_loss: 0.5599\n",
      "Epoch 19/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9978 - loss: 0.0153 - val_acc: 0.8718 - val_loss: 0.5823\n",
      "Epoch 20/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9980 - loss: 0.0142 - val_acc: 0.8702 - val_loss: 0.6040\n",
      "Fold #1: 0.8702399730682373\n",
      "Analizando fold: #2\n",
      "Epoch 1/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.6775 - loss: 0.6187 - val_acc: 0.8725 - val_loss: 0.4014\n",
      "Epoch 2/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.8862 - loss: 0.3537 - val_acc: 0.8877 - val_loss: 0.3078\n",
      "Epoch 3/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9162 - loss: 0.2521 - val_acc: 0.8902 - val_loss: 0.2788\n",
      "Epoch 4/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9378 - loss: 0.1938 - val_acc: 0.8906 - val_loss: 0.2758\n",
      "Epoch 5/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9468 - loss: 0.1661 - val_acc: 0.8896 - val_loss: 0.2773\n",
      "Epoch 6/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9564 - loss: 0.1442 - val_acc: 0.8893 - val_loss: 0.2860\n",
      "Epoch 7/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9611 - loss: 0.1272 - val_acc: 0.8846 - val_loss: 0.3035\n",
      "Epoch 8/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9662 - loss: 0.1150 - val_acc: 0.8838 - val_loss: 0.3109\n",
      "Epoch 9/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9690 - loss: 0.1063 - val_acc: 0.8824 - val_loss: 0.3216\n",
      "Epoch 10/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9743 - loss: 0.0897 - val_acc: 0.8810 - val_loss: 0.3372\n",
      "Epoch 11/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9797 - loss: 0.0758 - val_acc: 0.8803 - val_loss: 0.3573\n",
      "Epoch 12/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9801 - loss: 0.0710 - val_acc: 0.8784 - val_loss: 0.3774\n",
      "Epoch 13/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9834 - loss: 0.0640 - val_acc: 0.8686 - val_loss: 0.4327\n",
      "Epoch 14/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9854 - loss: 0.0567 - val_acc: 0.8738 - val_loss: 0.4162\n",
      "Epoch 15/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - acc: 0.9875 - loss: 0.0508 - val_acc: 0.8744 - val_loss: 0.4582\n",
      "Epoch 16/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9884 - loss: 0.0449 - val_acc: 0.8669 - val_loss: 0.5216\n",
      "Epoch 17/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9917 - loss: 0.0393 - val_acc: 0.8699 - val_loss: 0.4918\n",
      "Epoch 18/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9917 - loss: 0.0369 - val_acc: 0.8709 - val_loss: 0.5066\n",
      "Epoch 19/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9934 - loss: 0.0319 - val_acc: 0.8659 - val_loss: 0.5462\n",
      "Epoch 20/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9961 - loss: 0.0264 - val_acc: 0.8680 - val_loss: 0.5495\n",
      "Fold #2: 0.8679999709129333\n",
      "Analizando fold: #3\n",
      "Epoch 1/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7015 - loss: 0.5909 - val_acc: 0.8578 - val_loss: 0.3953\n",
      "Epoch 2/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.8971 - loss: 0.3305 - val_acc: 0.8808 - val_loss: 0.3128\n",
      "Epoch 3/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9226 - loss: 0.2395 - val_acc: 0.8958 - val_loss: 0.2730\n",
      "Epoch 4/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9397 - loss: 0.1894 - val_acc: 0.8947 - val_loss: 0.2729\n",
      "Epoch 5/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9513 - loss: 0.1557 - val_acc: 0.8965 - val_loss: 0.2795\n",
      "Epoch 6/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9568 - loss: 0.1362 - val_acc: 0.8835 - val_loss: 0.2937\n",
      "Epoch 7/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9645 - loss: 0.1171 - val_acc: 0.8906 - val_loss: 0.2983\n",
      "Epoch 8/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9715 - loss: 0.1010 - val_acc: 0.8770 - val_loss: 0.3301\n",
      "Epoch 9/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9753 - loss: 0.0886 - val_acc: 0.8845 - val_loss: 0.3311\n",
      "Epoch 10/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9776 - loss: 0.0799 - val_acc: 0.8835 - val_loss: 0.3494\n",
      "Epoch 11/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9846 - loss: 0.0667 - val_acc: 0.8822 - val_loss: 0.3720\n",
      "Epoch 12/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9847 - loss: 0.0615 - val_acc: 0.8682 - val_loss: 0.4235\n",
      "Epoch 13/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9891 - loss: 0.0484 - val_acc: 0.8766 - val_loss: 0.4319\n",
      "Epoch 14/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9919 - loss: 0.0416 - val_acc: 0.8755 - val_loss: 0.4556\n",
      "Epoch 15/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9950 - loss: 0.0312 - val_acc: 0.8755 - val_loss: 0.4741\n",
      "Epoch 16/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9944 - loss: 0.0304 - val_acc: 0.8704 - val_loss: 0.4891\n",
      "Epoch 17/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9969 - loss: 0.0222 - val_acc: 0.8746 - val_loss: 0.4992\n",
      "Epoch 18/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9976 - loss: 0.0177 - val_acc: 0.8746 - val_loss: 0.5241\n",
      "Epoch 19/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9984 - loss: 0.0158 - val_acc: 0.8490 - val_loss: 0.6828\n",
      "Epoch 20/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9970 - loss: 0.0159 - val_acc: 0.8702 - val_loss: 0.5717\n",
      "Fold #3: 0.8702399730682373\n",
      "Analizando fold: #4\n",
      "Epoch 1/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.6961 - loss: 0.5984 - val_acc: 0.8750 - val_loss: 0.3689\n",
      "Epoch 2/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.8974 - loss: 0.3193 - val_acc: 0.8800 - val_loss: 0.3113\n",
      "Epoch 3/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9188 - loss: 0.2390 - val_acc: 0.8878 - val_loss: 0.2852\n",
      "Epoch 4/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9356 - loss: 0.1905 - val_acc: 0.8926 - val_loss: 0.2680\n",
      "Epoch 5/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9473 - loss: 0.1594 - val_acc: 0.8859 - val_loss: 0.2935\n",
      "Epoch 6/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9528 - loss: 0.1429 - val_acc: 0.8864 - val_loss: 0.2952\n",
      "Epoch 7/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9604 - loss: 0.1228 - val_acc: 0.8862 - val_loss: 0.2972\n",
      "Epoch 8/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9673 - loss: 0.1071 - val_acc: 0.8856 - val_loss: 0.3139\n",
      "Epoch 9/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9748 - loss: 0.0892 - val_acc: 0.8765 - val_loss: 0.3615\n",
      "Epoch 10/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9760 - loss: 0.0816 - val_acc: 0.8830 - val_loss: 0.3546\n",
      "Epoch 11/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9797 - loss: 0.0713 - val_acc: 0.8770 - val_loss: 0.3869\n",
      "Epoch 12/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9842 - loss: 0.0595 - val_acc: 0.8779 - val_loss: 0.4005\n",
      "Epoch 13/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9883 - loss: 0.0498 - val_acc: 0.8736 - val_loss: 0.4429\n",
      "Epoch 14/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9906 - loss: 0.0442 - val_acc: 0.8749 - val_loss: 0.4464\n",
      "Epoch 15/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 0.9918 - loss: 0.0387 - val_acc: 0.8730 - val_loss: 0.4685\n",
      "Epoch 16/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9942 - loss: 0.0299 - val_acc: 0.8664 - val_loss: 0.5395\n",
      "Epoch 17/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9944 - loss: 0.0304 - val_acc: 0.8718 - val_loss: 0.5290\n",
      "Epoch 18/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9958 - loss: 0.0251 - val_acc: 0.8688 - val_loss: 0.5586\n",
      "Epoch 19/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9950 - loss: 0.0207 - val_acc: 0.8694 - val_loss: 0.5856\n",
      "Epoch 20/20\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - acc: 0.9983 - loss: 0.0144 - val_acc: 0.8699 - val_loss: 0.6137\n",
      "Fold #4: 0.869920015335083\n",
      "Media del k-fold: 0.8695999830961227\n",
      "Desviación típica del k-fold: 0.0009329568517813142\n"
     ]
    }
   ],
   "source": [
    "# Validación K-fold\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "from keras import models, layers\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.0\n",
    "    return results\n",
    "\n",
    "\n",
    "# Definir el modelo\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "    model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "# Cargar y preparar los datos\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "all_data = train_data#np.concatenate((train_data, test_data))\n",
    "all_labels = train_labels#np.concatenate((train_labels, test_labels))\n",
    "\n",
    "all_data = vectorize_sequences(all_data)\n",
    "all_labels = np.array(all_labels).astype('float32')\n",
    "\n",
    "k = 4  # Número de particiones\n",
    "folds_data = []\n",
    "folds_labels = []\n",
    "\n",
    "fold_size = int(len(all_data) / k)\n",
    "for fold in range(k):\n",
    "    print(f\"Creado fold: #{fold + 1}\")\n",
    "\n",
    "    folds_data.append(all_data[fold_size * fold: fold_size * (fold + 1)])\n",
    "    folds_labels.append(all_labels[fold_size * fold: fold_size * (fold + 1)])\n",
    "num_epochs = 20\n",
    "batch_size = 512\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "# Realizar K-Fold Cross-Validation\n",
    "for fold in range(k):\n",
    "    print(f\"Analizando fold: #{fold + 1}\")\n",
    "\n",
    "    fold_training_data = np.concatenate([folds_data[i] for i in range(k) if i != fold])\n",
    "    fold_test_data = folds_data[fold]\n",
    "\n",
    "    fold_training_labels = np.concatenate([folds_labels[i] for i in range(k) if i != fold])\n",
    "    fold_test_labels = folds_labels[fold]\n",
    "\n",
    "    # Crear un nuevo modelo\n",
    "    model = build_model()\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(\n",
    "        fold_training_data, fold_training_labels,\n",
    "        epochs=num_epochs, batch_size=batch_size,\n",
    "        validation_data=(fold_test_data, fold_test_labels)\n",
    "    )\n",
    "\n",
    "    # Evaluar el modelo en los datos de validación\n",
    "    val_loss, val_acc = model.evaluate(fold_test_data, fold_test_labels, verbose=0)\n",
    "    print(f\"Fold #{fold + 1}: {val_acc}\")\n",
    "\n",
    "    all_scores.append(val_acc)  # Guardar la puntuación\n",
    "\n",
    "# Calcular el promedio de las puntuaciones\n",
    "print(f\"Media del k-fold: {np.mean(all_scores)}\")\n",
    "print(f\"Desviación típica del k-fold: {np.std(all_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1a71e-7443-4b24-b002-f9a90f8a2347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76b397-a777-423a-a676-49e47a64abd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
